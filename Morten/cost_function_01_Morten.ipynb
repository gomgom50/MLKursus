{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SWMAL Exercise\n",
    "\n",
    "## Mathematical Foundation\n",
    "\n",
    "### Vector and matrix representation in python\n",
    "\n",
    "Say, we have $d$ features for a given sample point. This $d$-sized feature column vector for a data-sample $i$ is then given by\n",
    "\n",
    "$$\n",
    "    \\def\\rem#1{}\n",
    "    \\rem{ITMAL: CEF def and LaTeX commands, remember: no  newlines in defs}\n",
    "    \\def\\eq#1#2{#1 &=& #2\\\\}\n",
    "    \\def\\ar#1#2{\\begin{array}{#1}#2\\end{array}}\n",
    "    \\def\\ac#1#2{\\left[\\ar{#1}{#2}\\right]}\n",
    "    \\def\\st#1{_{\\scriptsize\\textrm{#1}}}\n",
    "    \\def\\norm#1{{\\cal L}_{#1}}\n",
    "    \\def\\obs#1#2{#1_{\\textrm{obs}}^{\\left(#2\\right)}}\n",
    "    \\def\\diff#1{\\mathrm{d}#1}\n",
    "    \\def\\pfrac#1#2{\\frac{\\partial~#1}{\\partial~#2}}\n",
    "    \\def\\dfrac#1#2{\\frac{\\mathrm{d}~#1}{\\mathrm{d}#2}}\n",
    "    \\def\\pown#1{^{(#1)}}\n",
    "    \\def\\pownn{\\pown{n}}\n",
    "    \\def\\powni{\\pown{i}}\n",
    "    \\def\\powtest{\\pown{\\scriptsize\\textrm{test}}}\n",
    "    \\def\\powtrain{\\pown{\\scriptsize\\textrm{train}}}\n",
    "    \\def\\pred{\\st{pred}}\n",
    "    \\def\\bM{\\mathbf{M}}\n",
    "    \\def\\bX{\\mathbf{X}}\n",
    "    \\def\\bZ{\\mathbf{Z}}\n",
    "    \\def\\bm{\\mathbf{m}}\n",
    "    \\def\\bx{\\mathbf{x}}\n",
    "    \\def\\by{\\mathbf{y}}\n",
    "    \\def\\bz{\\mathbf{z}}\n",
    "    \\def\\bw{\\mathbf{w}}\n",
    "    \\def\\btheta{{\\boldsymbol\\theta}}\n",
    "    \\def\\bSigma{{\\boldsymbol\\Sigma}}\n",
    "    \\def\\half{\\frac{1}{2}}\n",
    "\\bx\\powni = \n",
    "    \\ac{c}{\n",
    "        x_1\\powni \\\\\n",
    "        x_2\\powni \\\\ \n",
    "        \\vdots \\\\\n",
    "        x_d\\powni\n",
    "     }  \n",
    "$$\n",
    "\n",
    "or typically written transposed to save as\n",
    "\n",
    "$$\n",
    "    \\bx\\powni = \\left[  x_1\\powni~~ x_2\\powni~~ \\cdots~~ x_d\\powni\\right]^T\n",
    "$$\n",
    "\n",
    "such that $\\bX$ can be constructed of the full set of $n$ samples of these feature vectors\n",
    "\n",
    "$$\n",
    "    \\bX = \n",
    "      \\ac{c}{\n",
    "        (\\bx\\pown{1})^T \\\\\n",
    "        (\\bx\\pown{2})^T \\\\\n",
    "        \\vdots \\\\\n",
    "        (\\bx\\pownn)^T\n",
    "      }\n",
    "$$\n",
    "\n",
    "or by explicitly writing out the full data matrix $\\bX$ consisting of scalars \n",
    "\n",
    "$$\n",
    "    \\bX =\n",
    "        \\ac{cccc}{\n",
    "            x_1\\pown{1} & x_2\\pown{1} & \\cdots & x_d\\pown{1} \\\\\n",
    "            x_1\\pown{2} & x_2\\pown{2} & \\cdots & x_d\\pown{2}\\\\\n",
    "            \\vdots      &             &        & \\vdots \\\\\n",
    "            x_1\\pownn   & x_2\\pownn   & \\cdots & x_d\\pownn\\\\\n",
    "        }\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "but sometimes the notation is a little more fuzzy, leaving out the transpose operator for $\\mathbf x$ and in doing so just interpreting the $\\mathbf{x}^{(i)}$'s to be row vectors instead of column vectors.\n",
    "\n",
    "The target column vector, $\\mathbf y$, also has the dimension $n$ \n",
    "\n",
    "$$\n",
    "    \\by = \\ac{c}{\n",
    "            y\\pown{1} \\\\\n",
    "            y\\pown{2} \\\\\n",
    "            \\vdots \\\\\n",
    "            y\\pownn \\\\\n",
    "          }\n",
    "$$\n",
    "\n",
    "#### Qa Given the following $\\mathbf{x}^{(i)}$'s, construct and print the $\\mathbf X$ matrix in python.\n",
    "\n",
    "$$\n",
    "    \\ar{rl}{\n",
    "      \\bx\\pown{1} &= \\ac{c}{ 1, 2, 3}^T \\\\\n",
    "      \\bx\\pown{2} &= \\ac{c}{ 4, 2, 1}^T \\\\\n",
    "      \\bx\\pown{3} &= \\ac{c}{ 3, 8, 5}^T \\\\\n",
    "      \\bx\\pown{4} &= \\ac{c}{-9,-1, 0}^T\n",
    "    }\n",
    "$$\n",
    "\n",
    "##### Implementation Details\n",
    "\n",
    "Notice that the ```np.matrix``` class is getting deprecated! So, we use numpy's ```np.array``` as matrix container. Also, __do not__ use the built-in python lists or the numpy matrix subclass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix x:\n",
      " [[ 1  2  3]\n",
      " [ 4  2  1]\n",
      " [ 3  8  5]\n",
      " [-9 -1  0]]\n"
     ]
    }
   ],
   "source": [
    "# Qa\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "y = np.array([1,2,3,4]) # NOTE:  you'll need this later\n",
    "\n",
    "# TODO..create and print the full matrix\n",
    "\n",
    "X = np.array([[1,2,3],[4,2,1],[3,8,5],[-9,-1,0]])\n",
    "\n",
    "print(f\"Matrix x:\\n {X}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Norms, metrics or distances\n",
    "\n",
    "The $\\norm{2}$ Euclidian distance, or norm, for a vector of size $n$ is defined as \n",
    "\n",
    "$$\n",
    "    \\norm{2}:~~ ||\\bx||_2 = \\left( \\sum_{i=1}^{n} |x_i|^2 \\right)^{1/2}\\\\\n",
    "$$\n",
    "\n",
    "and the distance between two vectors is given by\n",
    "\n",
    "$$\n",
    "    \\ar{ll}{      \n",
    "          \\mathrm{d}(\\bx,\\by) &= ||\\bx-\\by||_2\\\\\n",
    "                     &= \\left( \\sum_{i=1}^n \\left| x_{i}-y_{i} \\right|^2 \\right)^{1/2}\n",
    "    }\n",
    "$$ \n",
    "\n",
    "This Euclidian norm is sometimes also just denoted as $||\\bx||$, leaving out the 2 in the subscript.\n",
    "\n",
    "The squared $\\norm{2}$ for a vector can compactly be expressed via \n",
    "\n",
    "$$\n",
    "    \\norm{2}^2: ||\\bx||_2^2 = \\bx^\\top\\bx\n",
    "$$\n",
    "\n",
    "\n",
    "The $\\norm{1}$ 'City-block' norm is given by\n",
    "\n",
    "$$\n",
    "    \\norm{1}:~~ ||\\bx||_1 = \\sum_i |x_i|\n",
    "$$\n",
    "\n",
    "but $\\norm{1}$ is not used as intensive as its more popular $\\norm{2}$ cousin. \n",
    "\n",
    "Notice that $|x|$ in code means ```fabs(x)```.\n",
    "\n",
    "#### Qb Implement the $\\norm{1}$ and $\\norm{2}$ norms for vectors in python.\n",
    "\n",
    "First implementation must be a 'low-level'/explicit implementation---using primitive/build-in functions, like ```+```, ```*``` and power ```**``` only! The square-root function can be achieved via power like ```x**0.5```.\n",
    "\n",
    "Do NOT use any methods from libraries, like ```math.sqrt```, ```math.abs```, ```numpy.linalg.inner```, ```numpy.dot()``` or similar. Yes, using such libraries is an efficient way of building python software, but in this exercise we want to explicitly map the mathematichal formulaes to python code.\n",
    "\n",
    "Name your functions L1 and L2 respectively, they both take one vector as input argument.\n",
    "\n",
    "But test your implementation against some built-in functions, say  ```numpy.linalg.norm```\n",
    "\n",
    "When this works, and passes the tests below, optimize the $\\norm{2}$, such that it uses np.numpy's dot operator instead of an explicit sum, call this function ```L2Dot```. This implementation, ```L2Dot```, must be pythonic, i.e. it must not contain explicit for- or while-loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tx-ty=[-2  3 -1 -2], d1-expected_d1=0.0, d2-expected_d2=0.0\n",
      "OK(part-1)\n",
      "d2dot-expected_d2= 0.0\n",
      "OK(part-2)\n"
     ]
    }
   ],
   "source": [
    "# TODO: solve Qb...implement the L1, L2 and L2Dot functions...\n",
    "def L1(vec):\n",
    "    if len(vec) == 1:\n",
    "        raise AssertionError(\"Must be a vector, not a scalar!\")\n",
    "    \n",
    "    v0 = 0\n",
    "    for v in vec:\n",
    "        if v < 0:\n",
    "            v = -v\n",
    "        v0 += v\n",
    "    \n",
    "    # return sum(abs(vec))\n",
    "    return v0\n",
    "\n",
    "def L2(vec):\n",
    "    if vec.ndim != 1:\n",
    "        raise AssertionError(\"Vector must be 1-dimensional!\")\n",
    "    v0 = 0\n",
    "    for v in vec:\n",
    "        v0 += (v**2)\n",
    "\n",
    "    v0 = v0**0.5\n",
    "    # return (sum(vec**2))**0.5\n",
    "    return v0\n",
    "        \n",
    "def L2Dot(vec):\n",
    "    if not isinstance(vec, np.ndarray):\n",
    "        raise ValueError(\"Wrong input type, must be numpy.ndarray\")\n",
    "    #return np.linalg.norm\n",
    "    return np.dot(vec.T,vec)**0.5\n",
    "\n",
    "# TEST vectors: here I test your implementation...calling your L1() and L2() functions\n",
    "tx=np.array([1, 2, 3, -1])\n",
    "ty=np.array([3,-1, 4,  1])\n",
    "\n",
    "expected_d1=8.0\n",
    "expected_d2=4.242640687119285\n",
    "\n",
    "d1=L1(tx-ty)\n",
    "d2=L2(tx-ty)\n",
    "\n",
    "print(f\"tx-ty={tx-ty}, d1-expected_d1={d1-expected_d1}, d2-expected_d2={d2-expected_d2}\")\n",
    "\n",
    "eps=1E-9 \n",
    "# NOTE: remember to import 'math' for fabs for the next two lines..\n",
    "import math as math\n",
    "assert math.fabs(d1-expected_d1)<eps, \"L1 dist seems to be wrong\" \n",
    "assert math.fabs(d2-expected_d2)<eps, \"L2 dist seems to be wrong\" \n",
    "\n",
    "print(\"OK(part-1)\")\n",
    "\n",
    "# comment-in once your L2Dot fun is ready...\n",
    "d2dot=L2Dot(tx-ty)\n",
    "print(\"d2dot-expected_d2=\",d2dot-expected_d2)\n",
    "assert math.fabs(d2dot-expected_d2)<eps, \"L2Ddot dist seem to be wrong\" \n",
    "print(\"OK(part-2)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The cost function, $J$\n",
    "\n",
    "Now, most ML algorithm uses norms or metrics internally when doing minimizations. Details on this will come later, but for now we need to know that an algorithm typically tries to minimize a given performance metric, the loss function, for all the input data, and implicitly tries to minimize the sum of all norms for the 'distances' between some predicted output, $y\\st{pred}$ and the true output $y\\st{true}$, with the distance between these typically given by the $\\norm{2}$ norm\n",
    "\n",
    "$$   \n",
    "  \\textrm{individual loss:}~~L\\powni = \\mathrm{d}(y\\st{pred}\\powni,y\\st{true}\\powni)\n",
    "$$ \n",
    "\n",
    "with $y\\st{pred}\\powni$, a scalar value, being the output from the hypothesis function, that maps the input vector $\\bx\\powni$ to a scalar\n",
    "\n",
    "$$ \n",
    "    y_{pred}\\powni = \\hat{y}\\powni = h(\\bx\\powni;\\btheta)\n",
    "$$\n",
    "\n",
    "and the total loss, $J$ will be the sum over all $i$'s\n",
    "\n",
    "$$\n",
    "    \\ar{rl}{\n",
    "        J &= \\frac{1}{n} \\sum_{i=1}^{n} L\\powni\\\\\n",
    "        &= \\frac{1}{n} \\sum_{i=1}^{n}\\mathrm{d}( h(\\bx\\powni) , y\\powni\\st{true})\n",
    "    }\n",
    "$$\n",
    "\n",
    "\n",
    "### Cost function in vector/matrix notation using $\\norm{2}$\n",
    "\n",
    "Remember the data-flow model for supervised learning\n",
    "\n",
    "<img src=\"https://itundervisning.ase.au.dk/SWMAL/L02/Figs/ml_simple_vector.png\" alt=\"WARNING: could not get image from server.\" style=\"width:500px\">\n",
    "\n",
    "Let us now express $J$ in terms of vectors and matrices instead of summing over individual scalars, and let's use $\\norm{2}$ as the distance function\n",
    "\n",
    "$$\n",
    "    \\ar{rl}{\n",
    "        J(\\bX,\\by;\\btheta) &= \\frac{1}{n} \\sum_{i=1}^{n} L\\powni\\\\\n",
    "        &= \\frac{1}{n}\\sum_{i=1}^{n} (h(\\bx\\powni) - \\by\\powni\\st{true})^2\\\\\n",
    "        &= \\frac{1}{n} ||h(\\bX) - \\by\\st{true} ||_2^2\\\\\n",
    "        &= \\frac{1}{n} ||\\by\\st{pred} - \\by\\st{true} ||_2^2\\\\\n",
    "     }\n",
    "$$\n",
    "\n",
    "with the matrix-vector notation\n",
    "\n",
    "$$ \n",
    "    \\by_{pred} = \\hat{\\by} =  h(\\bX;\\btheta)\n",
    "$$\n",
    "\n",
    "#### Loss or Objective Function using the Mean Squared Error\n",
    "\n",
    "This formulation is equal to the definition of the _mean-squared-error_, MSE (or indirectly also RMSE), here given in the general formulation for some random variable $Z$ \n",
    "\n",
    "$$\n",
    "    \\ar{rl}{\n",
    "        \\textrm{MSE} &= \\frac{1}{n} \\sum_{i=1}^{n} (\\hat{Z}_i-Z_i)^2 = \\frac{1}{n} SS\\\\\n",
    "        \\textrm{RMSE} &= \\sqrt{\\textrm{MSE}}\\\n",
    "    }\n",
    "$$\n",
    "\n",
    "with sum-of-squares (SS) is given simply by\n",
    "\n",
    "$$\n",
    "    \\textrm{SS} = \\sum_{i=1}^{n} (\\hat{Z}_i-Z_i)^2\\\\\n",
    "$$\n",
    "\n",
    "\n",
    "So, using the $\\norm{2}$ for the distance metric, is equal to saying that we want to minimize $J$ with respect to the MSE\n",
    "\n",
    "$$\n",
    "    \\ar{rl}{\n",
    "        J &= \\textrm{MSE}(h(\\bX), \\by\\st{true}) \\\\\n",
    "          &= \\textrm{MSE}(\\by\\st{pred}~, \\by\\st{true}) \\\\\n",
    "          &= \\textrm{MSE}(\\hat{\\by}, \\by\\st{true})\n",
    "     }\n",
    "$$\n",
    "\n",
    "Note: when minimizing one can ignore the constant factor $1/n$ and it really does not matter if you minimize MSE or RMSE. Often $J$ is also multiplied by 1/2 to ease notation when trying to differentiate it.\n",
    "\n",
    "$$\n",
    "    \\ar{rl}{\n",
    "        J(\\bX,\\by\\st{true};\\btheta) &\\propto \\half ||\\by\\st{pred} - \\by\\st{true} ||_2^2 \\\\\n",
    "          &\\propto \\textrm{MSE}\n",
    "     }\n",
    "$$\n",
    "\n",
    "### MSE\n",
    "\n",
    "Now, let us take a look on how you calculate the MSE.\n",
    "\n",
    "The MSE uses the $\\norm{2}$ norm internally, well, actually $||\\cdot||^2_2$ to be precise, and basically just sums, means and roots the individual (scalar) losses (distances), we just saw before. \n",
    "\n",
    "And the RMSE is just an MSE with a final square-root call.\n",
    "\n",
    "### Qc Construct the Root Mean Square Error (RMSE) function (Equation 2-1 [HOML]).\n",
    "\n",
    "Call the function RMSE, and evaluate it using the $\\bX$ matrix and $\\by$ from Qa.\n",
    "\n",
    "We implement a dummy hypothesis function, that just takes the first column of $\\bX$ as its 'prediction'\n",
    "\n",
    "$$\n",
    "    h\\st{dummy}(\\bX) = \\bX(:,0)\n",
    "$$\n",
    "\n",
    "Do not re-implement the $\\norm{2}$ for the RMSE function, but call the '''L2''' function you just implemented internally in RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE=6.576473218982953, diff=2.6645352591003757e-15\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# TODO: solve Qc...implement your RMSE function here\n",
    "def RMSE(X,y):\n",
    "    if not X.shape == y.shape:\n",
    "        raise ValueError(f\"The dimensions of inputs are incorrect.\\nX has shape: {X.shape}, while y has shape: {y.shape}\")\n",
    "    \n",
    "    m = len(X)\n",
    "\n",
    "    dvar = (1/m)**0.5 * L2(X-y)\n",
    "\n",
    "    RMSE =  dvar\n",
    "    return RMSE\n",
    "\n",
    "\n",
    "\n",
    "# Dummy h function:\n",
    "def h(X):    \n",
    "    if X.ndim!=2:\n",
    "        raise ValueError(\"expected X to be of ndim=2, got ndim=\",X.ndim)\n",
    "    if X.shape[0]==0 or X.shape[1]==0:\n",
    "        raise ValueError(\"X got zero data along the 0/1 axis, cannot continue\")\n",
    "    return X[:,0]\n",
    "\n",
    "# Calls your RMSE() function:\n",
    "\n",
    "r=RMSE(h(X),y)\n",
    "\n",
    "\n",
    "\n",
    "# TEST vector:\n",
    "eps=1E-9\n",
    "expected=6.57647321898295\n",
    "print(f\"RMSE={r}, diff={r-expected}\")\n",
    "assert math.fabs(r-expected)<eps, \"your RMSE dist seems to be wrong\" \n",
    "\n",
    "print(\"OK\")\n"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE\n",
    "\n",
    "#### Qd Similar construct the Mean Absolute Error (MAE) function (Equation 2-2 [HOML]) and evaluate it.\n",
    "\n",
    "The MAE will algorithmic wise be similar to the MSE part from using the $\\norm{1}$ instead of the $\\norm{2}$ norm.\n",
    "\n",
    "Again, re-implementation of the$\\norm{1}$ is a no-go, call the '''L1''' instead internally i MAE.\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "MAE=3.75, diff=0.0\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# TODO: solve Qd\n",
    "\n",
    "def MAE(X,y):\n",
    "    for i in range(len(X)):\n",
    "        if isinstance(X[i],np.complex128):\n",
    "            raise ValueError(\"Complex number spotted! \\nOnly real numbers please!\")\n",
    "        \n",
    "    if X.shape != y.shape:\n",
    "        raise ValueError(\"X and y must have the same shape!\")\n",
    "        \n",
    "    m = len(X)\n",
    "    print(type(X))\n",
    "\n",
    "    MAE = 1/m * L1(X-y)\n",
    "\n",
    "    return MAE\n",
    "    \n",
    "\n",
    "\n",
    "# Calls your MAE function:\n",
    "r=MAE(h(X), y)\n",
    "\n",
    "# TEST vector:\n",
    "expected=3.75\n",
    "print(f\"MAE={r}, diff={r-expected}\")\n",
    "assert math.fabs(r-expected)<eps, \"MAE dist seems to be wrong\" \n",
    "\n",
    "print(\"OK\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pythonic Code\n",
    "\n",
    "### Robustness of Code\n",
    "\n",
    "Data validity checking is an essential part of robust code, and in Python the 'fail-fast' method is used extensively: instead of lingering on trying to get the 'best' out of an erroneous situation, the fail-fast pragma will be very loud about any data inconsistencies at the earliest possible moment.\n",
    "\n",
    "Hence robust code should include a lot of error checking, say as pre- and post-conditions (part of the design-by-contract programming) when calling a function: when entering the function you check that all parameters are ok (pre-condition), and when leaving you check the return parameter (post-conditions).  \n",
    "\n",
    "Normally assert-checking or exception-throwing will do the trick just fine, with the exception method being more _pythonic_.\n",
    "\n",
    "For the norm-function you could, for instance, test your input data to be 'vector' like, i.e. like\n",
    "\n",
    "```python\n",
    "    assert x.shape[0]>=0 and x.shape[1]==0\n",
    "    \n",
    "    if not x.ndim==1:\n",
    "        raise some error\n",
    "```\n",
    "or similar.\n",
    "\n",
    "#### Qe Robust Code \n",
    "\n",
    "Add error checking code (asserts or exceptions), that checks for right $\\hat\\by$-$\\by$ sizes of the MSE and MAE functions.\n",
    "\n",
    "Also add error checking to all you previously tested L2() and L1() functions, and re-run all your tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: solve Qe...you need to modify your python cells above\n",
    "\n",
    "# All functions have been modified to some degree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qf Conclusion\n",
    "\n",
    "Now, conclude on all the exercise above. \n",
    "\n",
    "Write a short textual conclusion (max. 10- to 20-lines) that extract the _essence_ of the exercises: why did you think it was important to look at these particular ML concepts, and what was our overall learning outcome of the exercises (in broad terms).\n",
    "\n",
    "### Answer:\n",
    "\n",
    "Given the design matrix X at the beginning, I/we learned that it was important to fully understand the nomenclature behind how it is designed. Meaning that a row vector is \"disguised\" as a column vector in the design matrix. We had trouble in jthe beginning, thinking that we actually has to transpose the x(1), x(2)... and ended with a 3x4 matrix, instead of the correct 4x3 matrix.\n",
    "\n",
    "The first execise was good at testing how to write simple funcitons in \"pure\" math programming language, but I (Morten) at least decided to use the sum and abs functionality, instead of looping through values. There are outcommented code pieces that show the for loop functionality.\n",
    "\n",
    "The MSE/RMSE function gave us a good understanding of what it means, when we want to reduce the loss function, since relating it to linear algebra in terms of relating it to minimizing a distance makes great sense. I cant say that we feel as if we grasp the concept fully, but it makes more and more sense.\n",
    "\n",
    "Comparing the MAE and RMSE it seems that the RMSE is less robust than MAE, since its value is more influenced to squares and roots.\n",
    "\n",
    "The errorhandling exercise was fine, since it gave a better understanding of the functions, making sure that the inputs correspond to what we want the function to do. For example, we got to the exercise with the incorrect 3x4 design matrix, which the function used just fine, but gave an incorrect result. But when raising the check for equal dimensionality between h(X) and y, it became clear that the design matrix was incorrect.\n",
    "\n",
    "All in all, good exercises, though the errorhandling was a bit tedious (but good to learn and use in the future nonetheless)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REVISIONS||\n",
    ":- | :- |\n",
    "2018-12-18| CEF, initial.                  \n",
    "2019-01-31| CEF, spell checked and update. \n",
    "2019-02-04| CEF, changed d1/d2 in Qb to L1/L2. Fixe rev date error.\n",
    "2019-02-04| CEF, changed headline.\n",
    "2019-02-04| CEF, changed (.) in dist(x,y) to use pipes instead.\n",
    "2019-02-04| CEF, updated supervised learning fig, and changed , to ; for thetas, and change = to propto.\n",
    "2019-02-05| CEF, post lesson update, minor changes, added fabs around two test vectors.\n",
    "2019-02-07| CEF, updated def section. \n",
    "2019-09-01| CEF, updated for ITMAL v2.\n",
    "2019-09-04| CEF, updated for print-f and added conclusion Q.\n",
    "2019-09-05| CEF, fixed defect in print string and commented on fabs.\n",
    "2020-01-30| CEF, F20 ITMAL update.\n",
    "2020-02-03| CEF, minor text fixes.\n",
    "2020-02-24| CEF, elaborated on MAE and RMSE, emphasized not to use np functionality in L1 and L2.\n",
    "2020-09-03| CEF, E20 ITMAL update, updated figs paths.\n",
    "2020-09-06| CEF, added alt text.\n",
    "2020-09-07| CEF, updated HOML page refs.\n",
    "2021-01-12| CEF, F21 ITMAL update, moved revision table.\n",
    "2021-02-09| CEF, elaborated on test-vectors. Changed order of Design Matrix descriptions.\n",
    "2021-08-02| CEF, update to E21 ITMAL.\n",
    "2022-01-25| CEF, update to F22 SWMAL.\n",
    "2022-02-25| CEF, removed inner product equations.\n",
    "2022-08-30| CEF, updated to v1 changes.\n",
    "2023-02-07| CEF, minor update for d.\n",
    "2023-10-02| CEF, changed LaTeX commands to defs to get both KaTeX and MathJax to work."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
