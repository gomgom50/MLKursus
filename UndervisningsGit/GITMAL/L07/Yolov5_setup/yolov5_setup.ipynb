{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e255e646-1ecd-4039-9d7a-08ade6fdd477",
   "metadata": {},
   "source": [
    "# SWMAL\n",
    "\n",
    "## Setup of Yolov5 on GPU Cluster\n",
    "\n",
    "Most packages are ready on the GPU Cluster when you are running under an Anaconda 2021.11.\n",
    "\n",
    "We can finalize your setup both first cloning the Yolov5 git-repository"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e16ad43",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">NOTE: setup broken, fall 2023, under new Anaconda versions/new torch version!!</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5a2629-c4a8-4860-b904-5e40e6bd3cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "! (test ! -d yolov5 && git clone https://github.com/ultralytics/yolov5) || echo \"Git-repository already cloned..\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc588fa-ba32-4dc4-8a75-5b5564a2f12a",
   "metadata": {},
   "source": [
    "and then `pip` installing the missing packages (that are incompatible with a `conda` install). \n",
    "\n",
    "First we install a specific set of packages for the `torch` framework that will work with even the newest GPUs (3090 RTX), and let this run for about 2 to 15 min (its slow to install):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55858395-7d66-49db-9623-7ab13c802897",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install torch==1.10.1+cu111 torchvision==0.11.2+cu111 torchaudio==0.10.1 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c819bd-5b68-4f3c-b8e2-9c981e122a50",
   "metadata": {},
   "source": [
    "The we `pip` install whatever packages, that Yolov5 still needs  (since they are still incompatible with a `conda` install):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e7eab7-c847-4ff4-bc8c-ca34bb42df1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r yolov5_swmal_requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c242e453-49c0-4455-aab8-72297ed4e98e",
   "metadata": {},
   "source": [
    "You should now have the reqired setup for Yolov5, and I took care of installing specific GPU libraries needed for running Yolov5 on even the newest GPUs (3090). \n",
    "\n",
    "The user installed packages (found in you `~/.local/lib/python3.9/site-packages/` dir) now looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a7580f-b3f2-4942-8234-053120ad313b",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip list --user\n",
    "! echo ; echo \"DIR of local packages..\" ; echo\n",
    "! ls ~/.local/lib/python3.9/site-packages/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510d57eb-399c-4704-90f3-a4efd4bd3a3e",
   "metadata": {},
   "source": [
    "An now you can test out a demo of Yolov5 -- one that predicts on the image `Figs/zidane.jpg`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac6ad2d-5e41-4131-94e5-476b8ba41d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import torch\n",
    "import sys\n",
    "    \n",
    "def Versions():\n",
    "    print(\"VERSIONS:\")\n",
    "    print(f\"  sys.version                              = {sys.version}\")\n",
    "    print(f\"  torch.__version__                        = {torch.__version__}\")\n",
    "   \n",
    "    hasCuda = torch.cuda.is_available()\n",
    "    print(f\"  torch.cuda.is_available()                = {hasCuda}\")\n",
    "    if hasCuda:\n",
    "        print(f\"  torch.backends.cudnn.enabled             = {torch.backends.cudnn.enabled}\")\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(f\"  torch.cuda.get_device_properties(device) = {torch.cuda.get_device_properties(device)}\")\n",
    "        print(f\"  torch.tensor([1.0, 2.0]).cuda()          = {torch.tensor([1.0, 2.0]).cuda()}\")\n",
    "        \n",
    "\n",
    "def PredictDemo():\n",
    "    # Model\n",
    "    model = torch.hub.load('ultralytics/yolov5', 'yolov5s')  # or yolov5m, yolov5l, yolov5x, custom\n",
    "\n",
    "    # Images\n",
    "    #img = 'https://ultralytics.com/images/zidane.jpg'  # or file, Path, PIL, OpenCV, numpy, list\n",
    "    img = 'Figs/zidane.jpg'\n",
    "\n",
    "    # Inference\n",
    "    results = model(img)\n",
    "\n",
    "    # Results\n",
    "    results.print()  # or .show(), .save(), .crop(), .pandas(), etc.\n",
    "    #results.show()\n",
    "    results.save('temp.jpg')\n",
    "    \n",
    "Versions()\n",
    "PredictDemo()\n",
    "\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2211aee5",
   "metadata": {},
   "source": [
    "If succefull an output prediction image will be placed in the temp.jpg/ or in runs/detect/expNN so look for the output line from the cell, similar to\n",
    "\n",
    "```\n",
    "VERSIONS:\n",
    "  sys.version                              = 3.9.7 ...\n",
    "  torch.__version__                        = 1.11.0+cpu\n",
    "  torch.cuda.is_available()                = False\n",
    "\n",
    "Using cache found in C:\\Users\\au204573/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
    "YOLOv5  2022-4-3 torch 1.11.0+cpu CPU\n",
    "\n",
    "Fusing layers... \n",
    "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
    "Adding AutoShape... \n",
    "image 1/1: 720x1280 2 persons, 2 ties\n",
    "Speed: 31.6ms pre-process, 298.2ms inference, 2.2ms NMS per image at shape (1, 3, 384, 640)\n",
    "Saved 1 image to temp.jpg\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ba1888-371c-4b01-93e5-eec80f54e771",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "\n",
    "def ShowImg(imgfilename):\n",
    "    img = cv2.imread(imgfilename, 1)\n",
    "    img2 = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) #Converts from one colour space to the other\n",
    "\n",
    "    plt.imshow(img2)\n",
    "    plt.xticks([]), plt.yticks([])  # Hides the graph ticks and x / y axis\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "#ShowImg('runs/detect/exp2/zidane.jpg')\n",
    "ShowImg('temp.jpg/zidane.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f4191c",
   "metadata": {},
   "source": [
    "REVISIONS||\n",
    ":- | :- |\n",
    "2022-??-??| CEF, initial version, clone from [HOML].\n",
    "2023-10-12| CEF, added note on broken setup, needs check of new Anaconda and PyTorch versions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
