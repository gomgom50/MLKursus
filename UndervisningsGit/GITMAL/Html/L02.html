<!DOCTYPE html>
<html lang=da-Dk>
<!-- AUTOGENERATED HTML from CourseBuilder, CEF -->
<meta http-equiv='Content-Type' content='text/html; charset=utf-8'/>
<meta http-equiv='Cache-Control' content='no-cache, no-store, must-revalidate, max-age=0' />
<meta http-equiv='Pragma' content='no-cache' />
<meta http-equiv='Expires' content='0' />
<body style='font-family: times new roman, times, serif;font-size: 12pt;color: #000000;'>

<h3>Formål</h3>

<p>Vi lægger ud med at se på datamat-læring eller ML-læring via cost
funktionen, J, dvs.  hvordan en supervised ML algoritme i princippet kunne
tænkes at fungere.  Til cost funktionen tager vi hul på et par grundliggende
lineær algebra koncepter: &quot;norm&quot; eller afstandsmål mellem to N-dimensionale
vektorer, og vi ser hvordan Mean-Square-Error (MSE) og Mean-Absolute-Error
(MAE) kunne indgå i J.</p>

<p>Herefter studerer vi begrebet supervised klassifikation dybere og bruger
Scikit-learns fit-predict interface til konkret at lave og køre ML-kode.  Vi
går i detaljen med den fundamentale train/test-split og fit/predict proces vdr.
supervised learning, og vi bruger diverse kendte små dataset, som vi også vil
benytte i resten af kurset: MNIST, Iris og Moon.</p>

<p>Til sidst evaluere vi en kørt ML læring ved brug af diverse performance
metrics, dvs.  metoder til generelt at kvantificere hvor &#x27;god&#x27; (kvalitet) en
læring den pågældende algoritme har opnået på de pågældende data.</p>

<h3>Indhold</h3>

<ul>
<li>Lineær algebra og cost funktionen, J</li>
<ul>
<li>matricer, vektors, norms og NumPy,</li>
<li>MSE, MAE,</li>
<li>ML læring via J</li>
</ul>
<li>Supervised klassifikation</li>
<ul>
<li>’demo’ datasæt:  MNIST, iris and moon</li>
<li>fundamental ML supervised lærings-proces,</li>
<ol type='i'>
<li>forbered data: shuffle, stratification, normalization</li>
<li>train/test split</li>
<li>træn på træningsdata</li>
<li>evaluer på test data:  performance metrics</li>
</ol>
</ul>
<li>Performance metrics</li>
<ul>
<li>the accuracy paradox,</li>
<li>vigtige metrics,</li>
<ul>
<li>accuracy</li>
<li>precision_score</li>
<li>recall_score</li>
<li>f1_score</li>
<li>confusion_matrix</li>
</ul>
</ul>
</ul>

<h3>Litteratur</h3>

<ul style='list-style-type:none;'>
<li><i>§ 2 End-to-End Machine Learning Project, Select a Performance Measure</i> <span style='font-family: courier new, courier;'>&lbrack;HOML&rbrack;</span>,</li>
<ul><li>Genlæs KUN <i>§ Select a Performance Measure</i>, pp.39-41.</li></ul>
<li><i>§ 3 Classification</i> <span style='font-family: courier new, courier;'>&lbrack;HOML&rbrack;</span>,</li>
<ul><li>Skim eller spring over <i>§ The ROC Curve</i>, pp.97-100, <i>§ Multilabel Classification</i>
og <i>§ Multioutput Classification</i>, pp.106-108.</li></ul>
</ul>

<h3>Forberedelse inden lektionen</h3>

<ul>
<li>Læs litteraturen.</li>
</ul>

<h3>På klassen</h3>

<ol type='i'>
<li>Almindelig forelæsning</li>
<li><b>Opgave</b> (cost funktionen og lineær algebra):             <span style='font-family: courier new, courier;'><a href='https://itundervisning.ase.au.dk/SWMAL/L02/cost_function.ipynb' rel='noopener' target='_blank' download>cost_function.ipynb</a></span></li>
<li><b>Opgave</b> (supervised learning og fit-predict interfacet): <span style='font-family: courier new, courier;'><a href='https://itundervisning.ase.au.dk/SWMAL/L02/dummy_classifier.ipynb' rel='noopener' target='_blank' download>dummy_classifier.ipynb</a></span></li>
<li><b>Opgave</b> (performance metrikker):                         <span style='font-family: courier new, courier;'><a href='https://itundervisning.ase.au.dk/SWMAL/L02/performance_metrics.ipynb' rel='noopener' target='_blank' download>performance_metrics.ipynb</a></span></li>
</ol>

<h3>Slides</h3>

<ul style='list-style-type:none;'>
<li><span style='font-family: courier new, courier;'><a href='https://itundervisning.ase.au.dk/SWMAL/L02/lesson02.pdf' rel='noopener' target='_blank'>lesson02.pdf</a></span></li>
</ul>






</body>
</html>