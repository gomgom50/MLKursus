<!DOCTYPE html>
<html lang=da-Dk>
<!-- AUTOGENERATED HTML from CourseBuilder, CEF -->
<meta http-equiv='Content-Type' content='text/html; charset=utf-8'/>
<meta http-equiv='Cache-Control' content='no-cache, no-store, must-revalidate, max-age=0' />
<meta http-equiv='Pragma' content='no-cache' />
<meta http-equiv='Expires' content='0' />
<body style='font-family: times new roman, times, serif;font-size: 12pt;color: #000000;'>

<h3>Formål</h3>

<p>Kunstige neurale netværk (Artificial Neural Networks, ANN) er en af de
mest kendte machine learning modeller, og har en historisk baggrund med
inspiration i hjernen.</p>

<p>Vi skal se på modellen for det allermest udbredte neural netværk ,
Multi-Layer Perceptron (MLP), og se hvorledes det blot er en udvidelse af
lineær og logistisk regression.</p>

<p>Under vores behandling af MLP&#x27;er beskrives diverse basale koncepter vdr.
ANN&#x27;s f.eks.  input/skjulte/output lag, neuroner, aktiveringsfunktioner
osv.</p>

<p>Herudover diskuteres læringsmetoden, Backpropagation (BProp), for NN&#x27;s,
som blot er en udvidet for for gradient descent (GD), og endelig NN sættes
ind i et historisk perspektiv.</p>

<p>Endelig beskrives det nye interface &#x27;Keras&#x27;, som er en populær måde at
bygge NN&#x27;er op som  kan udnytte evt. hardware egnet til ML (læs GPU&#x27;er).</p>

<h3>Indhold</h3>

<ul>
<li>Neral Networks introduktion</li>
<ul><li>NN lag og navngivning</li></ul>
<ul><li>neuroner</li></ul>
<ul><li>aktiveringsfunktionen i en neuron</li></ul>
<li>Backpropagation (BProp)</li>
<li>Historisk perspektiv for NNs</li>
<li>Implementation af MLPs via Keras</li>
<ul><li>Categorical Encoding</li></ul>
<ul><li>Softmax Function</li></ul>
</ul>

<h3>Litteratur</h3>

<p>Der er en del gode kapitler i <span style='font-family: courier new, courier;'>&lbrack;HOML&rbrack;</span> vdr.  NN&#x27;s, men også en del ret
tekniske typisk vdr. TensorFlow, som I ikke bør sætte Jer ind i (med mindre
det er nødvendigt for Jeres projekter).</p>

<p>Derfor plukker jeg i <span style='font-family: courier new, courier;'>&lbrack;HOML&rbrack;</span> kapitel 10 og 11, så lektionens litteratur
bliver som nedenfor.</p>

<ul style='list-style-type:none;'>
<li><i>§ 10 Introduction to Artificial Neural Networks with Keras</i> <span style='font-family: courier new, courier;'>&lbrack;HOML&rbrack;</span>,</li>
<ul><li style='list-style-type:none;'>pp.279-296 2nd./pp.229-317 3rd., til og med <i>§ Implementing MLPs with Keras</i></li></ul>


<li>plus</li>
<ul><li style='list-style-type:none;'>pp.323-324 2nd./pp.349-350 3rd. <i>§ Number of Hidden Layers</i></li></ul>
<ul><li style='list-style-type:none;'>pp.325-325 2nd./pp.350-351 3rd. <i>§ Number of Neurons per Hidden Layer</i></li></ul>
<ul><li style='list-style-type:none;'>pp.325-327 2nd./pp.351-353 3rd. <i>§ Learning Rate, Batch Size, and Other Hyperparameters</i></li></ul>
<li><br>og</li>
<li><br><i>§ 11 Training Deep Neural Networks</i>, <span style='font-family: courier new, courier;'>&lbrack;HOML&rbrack;</span>,</li>
<ul><li style='list-style-type:none;'>pp.331-332 2nd./pp-357-358 3rd., til og med <i>§ Vanishing/Exploding Gradients Problems</i></li></ul>
<ul><li style='list-style-type:none;'>pp.335-338 2nd./pp-361-367 <i>§ Nonsaturating Activation Functions/§ Better Activation Functions</i></li></ul>
<ul><li style='list-style-type:none;'>til og eksklusivt p.338 2nd./p.367 3rd. <i>§ Batch Normalization</i></li></ul>
</ul>

<h3>Forberedelse inden lektionen</h3>

<ul>
<li>Læs litteraturen.</li>
<li>Installer Keras:</li>
<ul><li><span style='font-family: courier new, courier;'><a href='https://itundervisning.ase.au.dk/SWMAL/L06/Extra/installing_keras.ipynb' rel='noopener' target='_blank' download>installing_keras.ipynb</a></span></li></ul>
</ul>

<h3>På klassen</h3>

<ol type='i'>
<li>Almindelig forelæsning.</li>
<li><b>Demo</b> (keras setup, categorical):  <span style='font-family: courier new, courier;'><a href='https://itundervisning.ase.au.dk/SWMAL/L06/Extra/keras_to_categorical.ipynb' rel='noopener' target='_blank' download>keras_to_categorical.ipynb</a></span></li>
<li><b>Demo</b> (keras setup, softmax):      <span style='font-family: courier new, courier;'><a href='https://itundervisning.ase.au.dk/SWMAL/L06/Extra/softmax.ipynb' rel='noopener' target='_blank' download>softmax.ipynb</a></span></li>
<li><b>Opgave</b> (neurale net):             <span style='font-family: courier new, courier;'><a href='https://itundervisning.ase.au.dk/SWMAL/L06/ann.ipynb' rel='noopener' target='_blank' download>ann.ipynb</a></span></li>
</ol>

<h3>Slides</h3>

<ul style='list-style-type:none;'>
<li><span style='font-family: courier new, courier;'><a href='https://itundervisning.ase.au.dk/SWMAL/L06/lesson06.pdf' rel='noopener' target='_blank'>lesson06.pdf</a></span></li>
</ul>







</body>
</html>